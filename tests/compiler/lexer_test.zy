module tests.compiler.lexer

import compiler.lexer.{tokenize}
import compiler.lexer.token.{Token, TokenType}
import core.testing.{assert_eq, assert_true}

@test
fn test_basic_tokens() {
    source = "fn main() { }"
    result = tokenize(source, "test.seo")
    
    assert_true(result.is_ok())
    tokens = result.unwrap()
    
    assert_eq(tokens[0].type, TokenType.FN)
    assert_eq(tokens[1].type, TokenType.IDENTIFIER)
    assert_eq(tokens[1].value, "main")
    assert_eq(tokens[2].type, TokenType.LPAREN)
    assert_eq(tokens[3].type, TokenType.RPAREN)
    assert_eq(tokens[4].type, TokenType.LBRACE)
    assert_eq(tokens[5].type, TokenType.RBRACE)
}

@test
fn test_string_literal() {
    source = "\"Hello, World!\""
    result = tokenize(source, "test.seo")
    
    assert_true(result.is_ok())
    tokens = result.unwrap()
    
    assert_eq(tokens[0].type, TokenType.STRING_LIT)
    assert_eq(tokens[0].value, "Hello, World!")
}